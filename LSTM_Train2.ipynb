{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4a05bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.utils import resample "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c0ef90",
   "metadata": {},
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5a16b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.read_csv('/mnt/acropolis/akcigitlab/restricted/Publications/code/Data Analysis/Deniz_temp/LSTM_training_set.csv')\n",
    "ts = ts[ts.Name.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "325c1790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>Non Turkish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa</td>\n",
       "      <td>Non Turkish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aab</td>\n",
       "      <td>Non Turkish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aabakken</td>\n",
       "      <td>Non Turkish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aabaye</td>\n",
       "      <td>Non Turkish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name       family\n",
       "0         a  Non Turkish\n",
       "1        aa  Non Turkish\n",
       "2       aab  Non Turkish\n",
       "3  aabakken  Non Turkish\n",
       "4    aabaye  Non Turkish"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e11cd981",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.Name = ts.Name.str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52fa288e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Non Turkish                 532690\n",
       "Turkish                       7154\n",
       "Low Probability Turkish       1742\n",
       "High Probability Turkish       452\n",
       "Name: family, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.family.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8327d543",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.family = ts.family.replace('Low Probability Turkish', 'Non Turkish')\n",
    "ts.family = ts.family.replace('High Probability Turkish', 'Non Turkish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f923a379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_dataframe(df, random_state, target, _class = None): \n",
    "    if _class is not None:\n",
    "        df_minority = df[df[target] == _class]\n",
    "        df_majority = df.drop(df_minority.index.to_list())\n",
    "        df_minority_upsampled = resample(df_minority,\n",
    "                                     replace=True,\n",
    "                                     n_samples=df_majority.shape[0],\n",
    "                                     random_state=random_state)\n",
    "    else:\n",
    "        labels = df[target].unique() \n",
    "        value_counts = {} \n",
    "        for label in labels: \n",
    "            value_counts[label] = df[target].value_counts()[label] \n",
    "        minority = min(value_counts.items(), key=lambda x: x[1])[0] \n",
    "        majority = max(value_counts.items(), key=lambda x: x[1])[0] \n",
    "        df_minority = df[df[target] == minority] \n",
    "        df_majority = df[df[target] == majority] \n",
    "        df_minority_upsampled = resample(df_minority,\n",
    "                                         replace=True,\n",
    "                                         n_samples=value_counts[majority],\n",
    "                                         random_state=random_state) # reproducible results \n",
    "    df_upsampled = pd.concat([df_majority, df_minority_upsampled]) \n",
    "    return df_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3551991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = upsample_dataframe(ts[['Name', 'family']], 112233, 'family')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec56312b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Non Turkish    534884\n",
       "Turkish        534884\n",
       "Name: family, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.family.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1513f05",
   "metadata": {},
   "source": [
    "# Model Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6fdeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "NGRAMS = 2\n",
    "SAMPLE = 1062360\n",
    "EPOCHS = 15\n",
    "vect = CountVectorizer(analyzer='char', max_df=0.3, min_df=3, ngram_range=(NGRAMS, NGRAMS), lowercase=False) \n",
    "a = vect.fit_transform(ts.Name)\n",
    "vocab = vect.vocabulary_\n",
    "\n",
    "# sort n-gram by freq (highest -> lowest)\n",
    "words = []\n",
    "for b in vocab:\n",
    "    c = vocab[b]\n",
    "    #print(b, c, a[:, c].sum())\n",
    "    words.append((a[:, c].sum(), b))\n",
    "    #break\n",
    "words = sorted(words, reverse=True)\n",
    "words_list = [w[1] for w in words]\n",
    "num_words = len(words_list)\n",
    "print(\"num_words = %d\" % num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bcecfa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ngrams(text, n):\n",
    "    a = zip(*[text[i:] for i in range(n)])\n",
    "    wi = []\n",
    "    for i in a:\n",
    "        w = ''.join(i)\n",
    "        try:\n",
    "            idx = words_list.index(w)\n",
    "        except:\n",
    "            idx = 0\n",
    "        wi.append(idx)\n",
    "    return wi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b0669c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max feature len = 39, Avg. feature len = 5\n"
     ]
    }
   ],
   "source": [
    "X = np.array(ts.Name.apply(lambda c: find_ngrams(c, NGRAMS)))\n",
    "X_len = []\n",
    "for x in X:\n",
    "    X_len.append(len(x))\n",
    "max_feature_len = max(X_len)\n",
    "avg_feature_len = int(np.mean(X_len))\n",
    "print(\"Max feature len = %d, Avg. feature len = %d\" % (max_feature_len, avg_feature_len))\n",
    "y = np.array(ts.family.astype('category').cat.codes)\n",
    "ts['category_codes'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d72b7bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_categories = ts[['family', 'category_codes']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59d8d76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,  X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8a1ed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(columns = ['X', 'Y'])\n",
    "test['X'] = X_test\n",
    "test[\"Y\"] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f687d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concenate(row):\n",
    "    rv = ''\n",
    "    for i in row:\n",
    "        rv += str(i)\n",
    "    return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "023fbc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['X1'] = test.X.apply(lambda row: concenate(row)) \n",
    "test = test.drop_duplicates(subset = ['X1', 'Y'])\n",
    "X_test = np.array(test['X'])\n",
    "y_test = np.array(test[\"Y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23238f50",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "66e864ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e803226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = num_words # 20000\n",
    "feature_len = 25 # avg_feature_len # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2bfbdb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "855814 train sequences\n",
      "114114 test sequences\n",
      "Pad sequences (samples x time)\n",
      "X_train shape: (855814, 25)\n",
      "X_test shape: (114114, 25)\n",
      "2 classes\n",
      "Convert class vector to binary class matrix (for use with categorical_crossentropy)\n",
      "y_train shape: (855814, 2)\n",
      "y_test shape: (114114, 2)\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=feature_len)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=feature_len)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "print(num_classes, 'classes')\n",
    "\n",
    "print('Convert class vector to binary class matrix '\n",
    "      '(for use with categorical_crossentropy)')\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2680377e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 25, 32)            38976     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               82432     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 121,666\n",
      "Trainable params: 121,666\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, 32, input_length=feature_len))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4056b0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Epoch 1/15\n",
      "24070/24070 [==============================] - 537s 22ms/step - loss: 0.1611 - accuracy: 0.9398 - val_loss: 0.1065 - val_accuracy: 0.9647\n",
      "Epoch 2/15\n",
      "24070/24070 [==============================] - 533s 22ms/step - loss: 0.0972 - accuracy: 0.9685 - val_loss: 0.0728 - val_accuracy: 0.9781\n",
      "Epoch 3/15\n",
      "24070/24070 [==============================] - 530s 22ms/step - loss: 0.0745 - accuracy: 0.9774 - val_loss: 0.0590 - val_accuracy: 0.9826\n",
      "Epoch 4/15\n",
      "24070/24070 [==============================] - 531s 22ms/step - loss: 0.0644 - accuracy: 0.9810 - val_loss: 0.0536 - val_accuracy: 0.9841\n",
      "Epoch 5/15\n",
      "24070/24070 [==============================] - 531s 22ms/step - loss: 0.0584 - accuracy: 0.9830 - val_loss: 0.0485 - val_accuracy: 0.9858\n",
      "Epoch 6/15\n",
      "24070/24070 [==============================] - 531s 22ms/step - loss: 0.0544 - accuracy: 0.9842 - val_loss: 0.0480 - val_accuracy: 0.9861\n",
      "Epoch 7/15\n",
      "24070/24070 [==============================] - 531s 22ms/step - loss: 0.0524 - accuracy: 0.9848 - val_loss: 0.0485 - val_accuracy: 0.9858\n",
      "Epoch 8/15\n",
      "24070/24070 [==============================] - 529s 22ms/step - loss: 0.0509 - accuracy: 0.9852 - val_loss: 0.0443 - val_accuracy: 0.9873\n",
      "Epoch 9/15\n",
      "24070/24070 [==============================] - 529s 22ms/step - loss: 0.0494 - accuracy: 0.9857 - val_loss: 0.0464 - val_accuracy: 0.9867\n",
      "Epoch 10/15\n",
      "24070/24070 [==============================] - 531s 22ms/step - loss: 0.0484 - accuracy: 0.9861 - val_loss: 0.0515 - val_accuracy: 0.9852\n",
      "Epoch 11/15\n",
      "24070/24070 [==============================] - 528s 22ms/step - loss: 0.0475 - accuracy: 0.9862 - val_loss: 0.0486 - val_accuracy: 0.9862\n",
      "Epoch 12/15\n",
      "24070/24070 [==============================] - 529s 22ms/step - loss: 0.0467 - accuracy: 0.9865 - val_loss: 0.0437 - val_accuracy: 0.9877\n",
      "Epoch 13/15\n",
      "24070/24070 [==============================] - 529s 22ms/step - loss: 0.0455 - accuracy: 0.9869 - val_loss: 0.0482 - val_accuracy: 0.9864\n",
      "Epoch 14/15\n",
      "24070/24070 [==============================] - 526s 22ms/step - loss: 0.0453 - accuracy: 0.9869 - val_loss: 0.0463 - val_accuracy: 0.9868\n",
      "Epoch 15/15\n",
      "24070/24070 [==============================] - 528s 22ms/step - loss: 0.0451 - accuracy: 0.9871 - val_loss: 0.0465 - val_accuracy: 0.9868\n",
      "3567/3567 [==============================] - 11s 3ms/step - loss: 0.0824 - accuracy: 0.9765\n",
      "Test score: 0.08240486681461334\n",
      "Test accuracy: 0.9764971733093262\n"
     ]
    }
   ],
   "source": [
    "print('Train...')\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=EPOCHS,\n",
    "          validation_split=0.1, verbose=1)\n",
    "score, acc = model.evaluate(X_test, y_test,\n",
    "                            batch_size=batch_size, verbose=1)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "82794686",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./lstm_deniz.h5')\n",
    "words_df = pd.DataFrame(words_list, columns=['vocab'])\n",
    "words_df.to_csv('words_model.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5da93736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3567/3567 - 10s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non Turkish       1.00      0.97      0.99    106960\n",
      "     Turkish       0.73      1.00      0.84      7154\n",
      "\n",
      "    accuracy                           0.98    114114\n",
      "   macro avg       0.86      0.99      0.91    114114\n",
      "weighted avg       0.98      0.98      0.98    114114\n",
      "\n",
      "[[104278   2682]\n",
      " [     0   7154]]\n"
     ]
    }
   ],
   "source": [
    "p = model.predict(X_test, verbose=2) # to predict probability\n",
    "y_pred = np.argmax(p, axis=-1)\n",
    "target_names = list(ts.family.astype('category').cat.categories)\n",
    "print(classification_report(np.argmax(y_test, axis=1), y_pred, target_names=target_names))\n",
    "print(confusion_matrix(np.argmax(y_test, axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ae8a891",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = list(ts.family.astype('category').cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "48963876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_origin(names_list, target_names):\n",
    "    def find_ngrams(text, n):\n",
    "        a = zip(*[str(text)[i:] for i in range(n)])\n",
    "        wi = []\n",
    "        for i in a:\n",
    "            w = ''.join(i)\n",
    "            try:\n",
    "                idx = words_df.vocab.to_list().index(w)\n",
    "            except Exception as e:\n",
    "                idx = 0\n",
    "            wi.append(idx)\n",
    "        return wi\n",
    "\n",
    "    feature_len = 25\n",
    "    X = np.array(pd.Series(names_list).apply(lambda c: find_ngrams(c, 2)))\n",
    "    X_test = sequence.pad_sequences(X, maxlen=feature_len)\n",
    "    \n",
    "    df_dict = {'Name': names_list, \n",
    "               'Origin' : model.predict_classes(X_test, verbose=1)}\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(df_dict) \n",
    "    \n",
    "    target_names = {0: target_names[0], 1: target_names[1]}\n",
    "\n",
    "    df['Origin'] = df['Origin'].replace(target_names)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1019db7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-42-5fee052cfc5e>:19: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "1/1 [==============================] - 0s 532us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deniz tokmakoglu</td>\n",
       "      <td>Turkish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name   Origin\n",
       "0  deniz tokmakoglu  Turkish"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_origin(['deniz tokmakoglu'], target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11b79851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 487us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>napeleon boneparte</td>\n",
       "      <td>Non Turkish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name       Origin\n",
       "0  napeleon boneparte  Non Turkish"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_origin(['napeleon boneparte'], target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a38e03d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 616us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ufuk akcigit</td>\n",
       "      <td>Turkish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name   Origin\n",
       "0  ufuk akcigit  Turkish"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_origin(['ufuk akcigit'], target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8ebdeb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 583us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reyhan ayas</td>\n",
       "      <td>Turkish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name   Origin\n",
       "0  reyhan ayas  Turkish"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_origin(['reyhan ayas'], target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0990dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
